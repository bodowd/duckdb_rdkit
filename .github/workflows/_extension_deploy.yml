#
# Reusable workflow that deploys the artifacts produced by github.com/duckdb/duckdb/.github/workflows/_extension_distribution.yml
#
# note: this workflow needs to be located in the extension repository, as it requires secrets to be passed to the
# deploy script. However, it should generally not be necessary to modify this workflow in your extension repository, as
# this workflow can be configured to use a custom deploy script.


name: Extension Deployment
on:
  workflow_call:
    inputs:
      # The name of the extension
      extension_name:
        required: true
        type: string
      # DuckDB version to build against
      duckdb_version:
        required: true
        type: string
      # ';' separated list of architectures to exclude, for example: 'linux_amd64;osx_arm64'
      exclude_archs:
        required: false
        type: string
        default: ""
      # Whether to upload this deployment as the latest. This may overwrite a previous deployment.
      deploy_latest:
        required: false
        type: boolean
        default: false
      # Whether to upload this deployment under a versioned path. These will not be deleted automatically
      deploy_versioned:
        required: false
        type: boolean
        default: false
      # Postfix added to artifact names. Can be used to guarantee unique names when this workflow is called multiple times
      artifact_postfix:
        required: false
        type: string
        default: ""
      # Override the default deploy script with a custom script
      deploy_script:
        required: false
        type: string
        default: "./scripts/extension-upload.sh"
      # Override the default matrix parse script with a custom script
      matrix_parse_script:
        required: false
        type: string
        default: "./duckdb/scripts/modify_distribution_matrix.py"

jobs:
  generate_matrix:
    name: Generate matrix
    runs-on: ubuntu-latest
    outputs:
      deploy_matrix: ${{ steps.parse-matrices.outputs.deploy_matrix }}
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          submodules: 'true'

      - name: Checkout DuckDB to version
        run: |
          cd duckdb
          git checkout ${{ inputs.duckdb_version }}

      - name: Build RDKit - install conda
        run: | 
              sudo apt-get install g++ wget make libgl1-mesa-dev mesa-common-dev
              source ${CONDA}/etc/profile.d/conda.sh
              sudo chown -R ${USER} ${CONDA}
              conda config --set always_yes yes --set changeps1 no
              conda update -q conda
              conda info -a
              conda create --name rdkit_build $(python) cmake \
                  boost-cpp=$(boost_version) \
                  py-boost=$(boost_version) \
                  numpy pillow eigen pandas=2.0 matplotlib-base=3.7 \
                  qt=5.9.7 cairo
              conda activate rdkit_build
              conda install -c conda-forge pytest nbval ipykernel>=6.0
      - name: Build RDKit - Setup build environment
        run: |
            source ${CONDA}/etc/profile.d/conda.sh
            conda activate rdkit_build
            export CXXFLAGS="${CXXFLAGS} -Wall -Werror"
            mkdir build && cd build && \
            cmake .. \
            -DCMAKE_BUILD_TYPE=Release \
            -DRDK_INSTALL_INTREE=ON \
            -DRDK_INSTALL_STATIC_LIBS=OFF \
            -DRDK_BUILD_CPP_TESTS=ON \
            -DRDK_BUILD_PYTHON_WRAPPERS=ON \
            -DRDK_BUILD_COORDGEN_SUPPORT=ON \
            -DRDK_BUILD_MAEPARSER_SUPPORT=ON \
            -DRDK_OPTIMIZE_POPCNT=ON \
            -DRDK_BUILD_TEST_GZIP=ON \
            -DRDK_BUILD_FREESASA_SUPPORT=ON \
            -DRDK_BUILD_AVALON_SUPPORT=ON \
            -DRDK_BUILD_INCHI_SUPPORT=ON \
            -DRDK_BUILD_YAEHMOP_SUPPORT=ON \
            -DRDK_BUILD_XYZ2MOL_SUPPORT=ON \
            -DRDK_BUILD_CAIRO_SUPPORT=ON \
            -DRDK_BUILD_QT_SUPPORT=ON \
            -DQt5_DIR=/usr/lib/x86_64-linux-gnu/cmake/Qt5 \
            -DRDK_BUILD_SWIG_WRAPPERS=OFF \
            -DRDK_SWIG_STATIC=OFF \
            -DRDK_BUILD_THREADSAFE_SSS=ON \
            -DRDK_TEST_MULTITHREADED=ON \
            -DRDK_BUILD_CFFI_LIB=ON \
            -DBoost_NO_SYSTEM_PATHS=ON \
            -DBoost_NO_BOOST_CMAKE=TRUE \
            -DRDK_BOOST_PYTHON3_NAME=$(python_name) \
            -DPYTHON_EXECUTABLE=${CONDA_PREFIX}/bin/python3 \
            -DCMAKE_INCLUDE_PATH="${CONDA_PREFIX}/include" \
            -DCMAKE_LIBRARY_PATH="${CONDA_PREFIX}/lib"
       
      - name: Build RDKit - Configure build (Run CMake)
        run: |
              source ${CONDA}/etc/profile.d/conda.sh
              conda activate rdkit_build
              cd build
              make -j $( $(number_of_cores) ) install
      - name: Build RDKit - Build RDKit 
        run: |
              source ${CONDA}/etc/profile.d/conda.sh
              conda activate rdkit_build
              export RDBASE=`pwd`
              export PYTHONPATH=${RDBASE}:${PYTHONPATH}
              export LD_LIBRARY_PATH=${RDBASE}/lib:${CONDA_PREFIX}/lib:${LD_LIBRARY_PATH}
              echo "LD_LIBRARY_PATH: " $LD_LIBRARY_PATH
              export QT_QPA_PLATFORM='offscreen'
              cd build
              ctest -j $( $(number_of_cores) ) --output-on-failure -T Test
      - name: Build RDKit -  Run tests
        run: |
              source ${CONDA}/etc/profile.d/conda.sh
              conda activate rdkit_build
              conda install -c conda-forge ipython=8.12 sphinx myst-parser
              export RDBASE=`pwd`
              export PYTHONPATH=${RDBASE}:${PYTHONPATH}
              export LD_LIBRARY_PATH=${RDBASE}/lib:${LD_LIBRARY_PATH}
              export QT_QPA_PLATFORM='offscreen'
              cd Docs/Book
              make doctest


      - id: parse-matrices
        run: |
          python3 ${{ inputs.matrix_parse_script }} --input ./duckdb/.github/config/distribution_matrix.json --deploy_matrix --output deploy_matrix.json --exclude "${{ inputs.exclude_archs }}" --pretty
          deploy_matrix="`cat deploy_matrix.json`"
          echo deploy_matrix=$deploy_matrix >> $GITHUB_OUTPUT
          echo `cat $GITHUB_OUTPUT`

  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    needs: generate_matrix
    if: ${{ needs.generate_matrix.outputs.deploy_matrix != '{}' && needs.generate_matrix.outputs.deploy_matrix != '' }}
    strategy:
      matrix: ${{fromJson(needs.generate_matrix.outputs.deploy_matrix)}}

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          submodules: 'true'

      - name: Checkout DuckDB to version
        run: |
          cd duckdb
          git checkout ${{ inputs.duckdb_version }}

      - uses: actions/download-artifact@v2
        with:
          name: ${{ inputs.extension_name }}-${{ inputs.duckdb_version }}-extension-${{matrix.duckdb_arch}}${{inputs.artifact_postfix}}${{startsWith(matrix.duckdb, 'wasm') && '.wasm' || ''}}
          path: |
            /tmp/extension

      - name: Deploy
        shell: bash
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.S3_DEPLOY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DEPLOY_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.S3_REGION }}
          BUCKET_NAME: ${{ secrets.S3_BUCKET }}
          DUCKDB_EXTENSION_SIGNING_PK: ${{ secrets.S3_DUCKDB_ORG_EXTENSION_SIGNING_PK }}
        run: |
          pwd
          python3 -m pip install pip awscli
          git config --global --add safe.directory '*'
          cd duckdb
          git fetch --tags
          export DUCKDB_VERSION=`git tag --points-at HEAD`
          export DUCKDB_VERSION=${DUCKDB_VERSION:=`git log -1 --format=%h`}
          cd ..
          git fetch --tags
          export EXT_VERSION=`git tag --points-at HEAD`
          export EXT_VERSION=${EXT_VERSION:=`git log -1 --format=%h`}
          ${{ inputs.deploy_script }} ${{ inputs.extension_name }} $EXT_VERSION $DUCKDB_VERSION ${{ matrix.duckdb_arch }} $BUCKET_NAME ${{inputs.deploy_latest || 'true' && 'false'}} ${{inputs.deploy_versioned || 'true' && 'false'}}
